---
title: "Intel® RealSense – Next Gen 3D Interfaces"
subtitle: "Now with upcoming Depth camera in mobile phone and tablets, our primary device will be better at sensing its surroundings. Can we create a more immersive content consumption medium using this technology?"
layout: post-project
date: 2014-04-29 10:20
categories: project
tags:
 - Intel Perceptual Computing SDK
 - 3D gestures
 - Publication Industry
author: Aniket Handa
size: 2
permalink: /RS.html
imagesrc: "/theme/img/icons/icon-3d.png"
summary: ""
---
*This is an ongoing project*

As technology becomes more ambient and hides itself in the environment, it is becoming more obvious that the next paradigm of user interface could be a based on natural 3D gestures. Industry is bringing the technology to the devices such as tablets and smartphones [[1]](http://www.theverge.com/2014/1/6/5281120/kinect-like-cameras-are-coming-to-your-next-laptop-or-tablet), whereas research is being done to integrate the technology with wearable devices [[2]](http://dl.acm.org/citation.cfm?id=2502042). Devices such as smart watches deal with limited display to touch and also head mounted displays (like Google glass) deal with awkward interaction techniques, can be a good candidate for using 3D gestures as input. HCI can play a major role in defining interactions to provide all together new experience to the user. It can also explore new domains wherein this technology can be used by carefully considering the value provided by it as compared to existing solutions.

[Check out our progress here](http://dynabots.com)

			